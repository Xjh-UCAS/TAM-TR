# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.optimize import linear_sum_assignment

from ultralytics.utils.metrics import bbox_iou
from ultralytics.utils.ops import xywh2xyxy, xyxy2xywh

#åŒˆç‰™åˆ©åŒ¹é…ä½ç½®
class HungarianMatcher(nn.Module):
    """
    A module implementing the HungarianMatcher, which is a differentiable module to solve the assignment problem in an
    end-to-end fashion.

    HungarianMatcher performs optimal assignment over the predicted and ground truth bounding boxes using a cost
    function that considers classification scores, bounding box coordinates, and optionally, mask predictions.

    Attributes:
        cost_gain (dict): Dictionary of cost coefficients: 'class', 'bbox', 'giou', 'mask', and 'dice'.
        use_fl (bool): Indicates whether to use Focal Loss for the classification cost calculation.
        with_mask (bool): Indicates whether the model makes mask predictions.
        num_sample_points (int): The number of sample points used in mask cost calculation.
        alpha (float): The alpha factor in Focal Loss calculation.
        gamma (float): The gamma factor in Focal Loss calculation.

    Methods:
        forward(pred_bboxes, pred_scores, gt_bboxes, gt_cls, gt_groups, masks=None, gt_mask=None): Computes the
            assignment between predictions and ground truths for a batch.
        _cost_mask(bs, num_gts, masks=None, gt_mask=None): Computes the mask cost and dice cost if masks are predicted.
    """

    def __init__(self, cost_gain=None, use_fl=True, with_mask=False, num_sample_points=12544, alpha=0.25, gamma=2.0):
        """Initializes HungarianMatcher with cost coefficients, Focal Loss, mask prediction, sample points, and alpha
        gamma factors.
        """
        super().__init__()
        if cost_gain is None:
            cost_gain = {'class': 1, 'bbox': 5, 'giou': 2, 'mask': 1, 'dice': 1}
        self.cost_gain = cost_gain
        self.use_fl = use_fl
        self.with_mask = with_mask
        self.num_sample_points = num_sample_points
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, pred_bboxes, pred_scores, gt_bboxes, gt_cls, gt_groups, masks=None, gt_mask=None):
        """
        Forward pass for HungarianMatcher. This function computes costs based on prediction and ground truth
        (classification cost, L1 cost between boxes and GIoU cost between boxes) and finds the optimal matching between
        predictions and ground truth based on these costs.

        Args:
            pred_bboxes (Tensor): Predicted bounding boxes with shape [batch_size, num_queries, 4].
            pred_scores (Tensor): Predicted scores with shape [batch_size, num_queries, num_classes].
            gt_cls (torch.Tensor): Ground truth classes with shape [num_gts, ].
            gt_bboxes (torch.Tensor): Ground truth bounding boxes with shape [num_gts, 4].
            gt_groups (List[int]): List of length equal to batch size, containing the number of ground truths for
                each image.
            masks (Tensor, optional): Predicted masks with shape [batch_size, num_queries, height, width].
                Defaults to None.
            gt_mask (List[Tensor], optional): List of ground truth masks, each with shape [num_masks, Height, Width].
                Defaults to None.

        Returns:
            (List[Tuple[Tensor, Tensor]]): A list of size batch_size, each element is a tuple (index_i, index_j), where:
                - index_i is the tensor of indices of the selected predictions (in order)
                - index_j is the tensor of indices of the corresponding selected ground truth targets (in order)
                For each batch element, it holds:
                    len(index_i) = len(index_j) = min(num_queries, num_target_boxes)
        """

        bs, nq, nc = pred_scores.shape

        if sum(gt_groups) == 0:
            return [(torch.tensor([], dtype=torch.long), torch.tensor([], dtype=torch.long)) for _ in range(bs)]

        # We flatten to compute the cost matrices in a batch
        # [batch_size * num_queries, num_classes]
        if not pred_scores.is_contiguous():
            pred_scores = pred_scores.contiguous()
        pred_scores = pred_scores.detach().view(-1, nc)
        pred_scores = F.sigmoid(pred_scores) if self.use_fl else F.softmax(pred_scores, dim=-1)
        # [batch_size * num_queries, 4]
        pred_bboxes = pred_bboxes.detach().view(-1, 4)

        # Compute the classification cost åŒˆç‰™åˆ©åˆ†é…æ ‡ç­¾
        pred_scores = pred_scores[:, gt_cls] #æ ¹æ®çœŸå®ç›®æ ‡ç±»åˆ«ï¼ˆgt_clsï¼‰æå–é¢„æµ‹åˆ†æ•°ï¼ˆpred_scoresï¼‰ä¸­çš„å¯¹åº”ç±»åˆ«å¾—åˆ†ï¼Œ[batch_size * num_queries, num_gts]
        if self.use_fl: #å¦‚æœä½¿ç”¨focal loss
            neg_cost_class = (1 - self.alpha) * (pred_scores ** self.gamma) * (-(1 - pred_scores + 1e-8).log())
            pos_cost_class = self.alpha * ((1 - pred_scores) ** self.gamma) * (-(pred_scores + 1e-8).log())
            cost_class = pos_cost_class - neg_cost_class
        else:
            cost_class = -pred_scores #è¿™é‡Œä¸ºä»€ä¹ˆç›´æ¥ç»™è´Ÿæ•°å‘¢ï¼Ÿ

        # Compute the L1 cost between boxes
        cost_bbox = (pred_bboxes.unsqueeze(1) - gt_bboxes.unsqueeze(0)).abs().sum(-1)  # (bs*num_queries, num_gt)

        # Compute the GIoU cost between boxes, (bs*num_queries, num_gt)
        cost_giou = 1.0 - bbox_iou(pred_bboxes.unsqueeze(1), gt_bboxes.unsqueeze(0), xywh=True, RIOU=True).squeeze(-1)

        # Final cost matrix
        C = self.cost_gain['class'] * cost_class + \
            self.cost_gain['bbox'] * cost_bbox + \
            self.cost_gain['giou'] * cost_giou
        # Compute the mask cost and dice cost
        if self.with_mask:
            C += self._cost_mask(bs, gt_groups, masks, gt_mask)

        # Set invalid values (NaNs and infinities) to 0 (fixes ValueError: matrix contains invalid numeric entries)
        C[C.isnan() | C.isinf()] = 0.0

        C = C.view(bs, nq, -1).cpu()
        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(gt_groups, -1))]
        gt_groups = torch.as_tensor([0, *gt_groups[:-1]]).cumsum_(0)
        # (idx for queries, idx for gt)
        return [(torch.tensor(i, dtype=torch.long), torch.tensor(j, dtype=torch.long) + gt_groups[k])
                for k, (i, j) in enumerate(indices)]

    # This function is for future RT-DETR Segment models
    # def _cost_mask(self, bs, num_gts, masks=None, gt_mask=None):
    #     assert masks is not None and gt_mask is not None, 'Make sure the input has `mask` and `gt_mask`'
    #     # all masks share the same set of points for efficient matching
    #     sample_points = torch.rand([bs, 1, self.num_sample_points, 2])
    #     sample_points = 2.0 * sample_points - 1.0
    #
    #     out_mask = F.grid_sample(masks.detach(), sample_points, align_corners=False).squeeze(-2)
    #     out_mask = out_mask.flatten(0, 1)
    #
    #     tgt_mask = torch.cat(gt_mask).unsqueeze(1)
    #     sample_points = torch.cat([a.repeat(b, 1, 1, 1) for a, b in zip(sample_points, num_gts) if b > 0])
    #     tgt_mask = F.grid_sample(tgt_mask, sample_points, align_corners=False).squeeze([1, 2])
    #
    #     with torch.cuda.amp.autocast(False):
    #         # binary cross entropy cost
    #         pos_cost_mask = F.binary_cross_entropy_with_logits(out_mask, torch.ones_like(out_mask), reduction='none')
    #         neg_cost_mask = F.binary_cross_entropy_with_logits(out_mask, torch.zeros_like(out_mask), reduction='none')
    #         cost_mask = torch.matmul(pos_cost_mask, tgt_mask.T) + torch.matmul(neg_cost_mask, 1 - tgt_mask.T)
    #         cost_mask /= self.num_sample_points
    #
    #         # dice cost
    #         out_mask = F.sigmoid(out_mask)
    #         numerator = 2 * torch.matmul(out_mask, tgt_mask.T)
    #         denominator = out_mask.sum(-1, keepdim=True) + tgt_mask.sum(-1).unsqueeze(0)
    #         cost_dice = 1 - (numerator + 1) / (denominator + 1)
    #
    #         C = self.cost_gain['mask'] * cost_mask + self.cost_gain['dice'] * cost_dice
    #     return C

#åˆ›å»ºç”¨äº denoisingï¼ˆå»å™ªï¼‰è¿‡ç¨‹çš„æŸ¥è¯¢ç»„
def get_cdn_group(batch,
                  num_classes,
                  num_queries,
                  class_embed,
                  num_dn=100,
                  cls_noise_ratio=0.5,
                  box_noise_scale=1.0,
                  training=False):
    """
    Get contrastive denoising training group. This function creates a contrastive denoising training group with positive
    and negative samples from the ground truths (gt). It applies noise to the class labels and bounding box coordinates,
    and returns the modified labels, bounding boxes, attention mask and meta information.
    è·å¾—å¯¹æ¯”å»å™ªè®­ç»ƒç»„ã€‚ è¯¥å‡½æ•°ä½¿ç”¨æ¥è‡ªåŸºæœ¬äº‹å® (gt) çš„æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬åˆ›å»ºå¯¹æ¯”å»å™ªè®­ç»ƒç»„ã€‚ å®ƒå°†å™ªå£°åº”ç”¨äºç±»æ ‡ç­¾å’Œè¾¹ç•Œæ¡†åæ ‡ï¼Œå¹¶è¿”å›ä¿®æ”¹åçš„æ ‡ç­¾ã€è¾¹ç•Œæ¡†ã€æ³¨æ„åŠ›æ©ç å’Œå…ƒä¿¡æ¯ã€‚
    Args:
        batch (dict): A dict that includes 'gt_cls' (torch.Tensor with shape [num_gts, ]), 'gt_bboxes'
            (torch.Tensor with shape [num_gts, 4]), 'gt_groups' (List(int)) which is a list of batch size length
            indicating the number of gts of each image.
            å®ƒæ˜¯æ‰¹å¤§å°é•¿åº¦çš„åˆ—è¡¨ï¼ŒæŒ‡ç¤ºæ¯ä¸ªå›¾åƒçš„ gts æ•°é‡ã€‚
        num_classes (int): Number of classes.
        num_queries (int): Number of queries.
        class_embed (torch.Tensor): Embedding weights to map class labels to embedding space.
        num_dn (int, optional): Number of denoising. Defaults to 100.
        cls_noise_ratio (float, optional): Noise ratio for class labels. Defaults to 0.5.
        box_noise_scale (float, optional): Noise scale for bounding box coordinates. Defaults to 1.0.
        training (bool, optional): If it's in training mode. Defaults to False.

    Returns:
        (Tuple[Optional[Tensor], Optional[Tensor], Optional[Tensor], Optional[Dict]]): The modified class embeddings,
            bounding boxes, attention mask and meta information for denoising. If not in training mode or 'num_dn'
            is less than or equal to 0, the function returns None for all elements in the tuple.
    """

    if (not training) or num_dn <= 0:
        return None, None, None, None
    # è¿™æ®µä»£ç è·å–äº†è¾“å…¥ batch ä¸­çš„ gt_groupsï¼Œè®¡ç®—äº†æ€»çš„ ground truth æ•°é‡ä»¥åŠæ‰¹æ¬¡ä¸­æœ€å¤§çš„ ground truth æ•°é‡ã€‚
    # å¦‚æœæœ€å¤§æ•°é‡ä¸º 0ï¼Œåˆ™è¯´æ˜æ²¡æœ‰ ground truthï¼Œç›´æ¥è¿”å› Noneã€‚
    gt_groups = batch['gt_groups']
    total_num = sum(gt_groups) # æ‰€æœ‰å›¾åƒä¸­ä¸€å…±æœ‰å¤šå°‘gts
    max_nums = max(gt_groups) # æ‰€æœ‰å›¾åƒä¸­æœ€å¤§çš„gtså€¼
    if max_nums == 0:
        return None, None, None, None
    # è¿™æ®µä»£ç è®¡ç®—äº†æ¯ä¸ªæ ·æœ¬ç»„ä¸­çš„å¯¹æ¯”å»å™ªæ•°é‡ï¼Œå¹¶ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç»„ã€‚ç»„æ•°ä¸º 100/æœ€å¤§çš„gtså€¼
    num_group = num_dn // max_nums 
    num_group = 1 if num_group == 0 else num_group
    # Pad gt to max_num of a batch
    bs = len(gt_groups)
    gt_cls = batch['cls']  # (bs*num, ) [num_gts, ] # [0,1,2,3,4,0,1,2,3,4]
    gt_bbox = batch['bboxes']  # bs*num, 4 [num_gts, 4]
    b_idx = batch['batch_idx']

    # Each group has positive and negative queries.
    dn_cls = gt_cls.repeat(2 * num_group)  # (2*num_group*bs*num, ) å¤åˆ¶ä¸¤ä»½ä»¥åŠåˆ†ç»„ç”¨äºç”Ÿäº§dn
    dn_bbox = gt_bbox.repeat(2 * num_group, 1)  # 2*num_group*bs*num, 4
    dn_b_idx = b_idx.repeat(2 * num_group).view(-1)  # (2*num_group*bs*num, )

    # Positive and negative mask
    # (bs*num*num_group, ), the second total_num*num_group part as negative samples
    # PyTorch ä¸­çš„ torch.arange å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªä» 0 åˆ° total_num * num_group - 1 çš„æ•´æ•°åºåˆ— 
    # ç”±äº total_num * num_group ä»£è¡¨äº†æ€»çš„æ ·æœ¬æ•°é‡ï¼Œæ‰€ä»¥åŠ ä¸Šè¿™ä¸ªå€¼ç›¸å½“äºå°†åºåˆ—ä¸­çš„ç´¢å¼•ç§»åŠ¨åˆ°è¡¨ç¤ºè´Ÿæ ·æœ¬çš„ä½ç½®ã€‚
    neg_idx = torch.arange(total_num * num_group, dtype=torch.long, device=gt_bbox.device) + num_group * total_num

    if cls_noise_ratio > 0:
        # Half of bbox prob
        mask = torch.rand(dn_cls.shape) < (cls_noise_ratio * 0.5) #æ ¹æ®æ¦‚ç‡æœ‰å››åˆ†ä¹‹ä¸€çš„çš„maskä¸ºtrueï¼ˆ1ï¼‰ï¼Œå››åˆ†ä¹‹ä¸‰ä¸ºfalseï¼ˆ0ï¼‰ä¿ç•™åŸå¼ é‡ç»´åº¦
        idx = torch.nonzero(mask).squeeze(-1) #è·å–è¦æ·»åŠ å™ªå£°çš„ç´¢å¼•
        # Randomly put a new one here
        new_label = torch.randint_like(idx, 0, num_classes, dtype=dn_cls.dtype, device=dn_cls.device) # éšæœºæ”¾ä¸€ä¸ªæ–°çš„ç±»åˆ«
        dn_cls[idx] = new_label

    if box_noise_scale > 0:
        # å°†è¾¹ç•Œæ¡†åæ ‡ dn_bbox ä» (x_center, y_center, width, height) çš„æ ¼å¼è½¬æ¢ä¸º (x_min, y_min, x_max, y_max) çš„æ ¼å¼ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ known_bbox ä¸­ã€‚
        known_bbox = xywh2xyxy(dn_bbox)
        # é¦–å…ˆï¼Œå®ƒä» dn_bbox çš„æœ€åä¸¤ä¸ªç»´åº¦ï¼ˆå³å®½åº¦å’Œé«˜åº¦ï¼‰ä¸­æå–äº†å€¼ï¼Œç„¶åä¹˜ä»¥ 0.5ï¼Œè¡¨ç¤ºå™ªå£°èŒƒå›´ä¸ºè¾¹ç•Œæ¡†å®½åº¦å’Œé«˜åº¦çš„ä¸€åŠã€‚
        # æ¥ç€ï¼Œä½¿ç”¨ repeat() æ–¹æ³•å°†è¿™ä¸ªç»“æœæ²¿ç€ç¬¬äºŒç»´é‡å¤äº†ä¸¤æ¬¡ï¼Œä»¥ä¾¿åº”ç”¨äºæ¯ä¸ªè¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦
        diff = (dn_bbox[..., 2:] * 0.5).repeat(1, 2) * box_noise_scale  # 2*num_group*bs*num, 4
        # è¿™è¡Œä»£ç ç”Ÿæˆäº†ä¸€ä¸ªä¸ dn_bbox å¼ é‡ç›¸åŒå½¢çŠ¶çš„éšæœºæ•´æ•°å¼ é‡ï¼Œå€¼ä¸º 0 æˆ– 1ï¼Œå¹¶ä¹˜ä»¥ 2.0 åå‡å» 1.0ï¼Œå¾—åˆ°äº†ä¸€ä¸ªåŒ…å« -1 å’Œ 1 çš„å¼ é‡ï¼Œç”¨äºè¡¨ç¤ºå™ªå£°çš„æ–¹å‘ï¼ˆå·¦å³ä¸Šä¸‹ï¼‰
        rand_sign = torch.randint_like(dn_bbox, 0, 2) * 2.0 - 1.0
        # è¿™è¡Œä»£ç ç”Ÿæˆäº†ä¸€ä¸ªä¸ dn_bbox å¼ é‡ç›¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡ï¼Œå…¶ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä»å‡åŒ€åˆ†å¸ƒ [0, 1) ä¸­éšæœºé‡‡æ ·çš„ã€‚
        rand_part = torch.rand_like(dn_bbox)
        # è¿™è¡Œä»£ç å¯¹éƒ¨åˆ†éšæœºå™ªå£°å¢åŠ äº† 1.0ï¼Œç”¨äºç”Ÿæˆä¸€éƒ¨åˆ†è¾¹ç•Œæ¡†çš„å™ªå£°ï¼Œç¡®ä¿å®ƒä»¬æ˜¯è´Ÿæ ·æœ¬ã€‚è®©è¿™éƒ¨åˆ†æ ·æœ¬åœ¨[1,2]ä¹‹é—´ï¼Œè¿œç¦»çœŸå®å€¼å½¢æˆè´Ÿæ ·æœ¬
        rand_part[neg_idx] += 1.0
        # è¿™è¡Œä»£ç å°†éšæœºå™ªå£°ä¹˜ä»¥éšæœºæ–¹å‘ï¼Œä»¥è·å–æœ€ç»ˆçš„å™ªå£°å€¼
        rand_part *= rand_sign
        #  è¿™è¡Œä»£ç å°†å™ªå£°åº”ç”¨åˆ°è¾¹ç•Œæ¡†çš„åæ ‡ä¸Šã€‚
        known_bbox += rand_part * diff
        # è¿™è¡Œä»£ç ç¡®ä¿è¾¹ç•Œæ¡†çš„åæ ‡åœ¨åˆç†çš„èŒƒå›´å†…ï¼Œå³åœ¨å›¾åƒèŒƒå›´å†…ã€‚
        known_bbox.clip_(min=0.0, max=1.0)
        dn_bbox = xyxy2xywh(known_bbox)
        dn_bbox = torch.logit(dn_bbox, eps=1e-6)  # inverse sigmoid

    num_dn = int(max_nums * 2 * num_group)  # total denoising queries
    # class_embed = self.denoising_class_embed.weght = nn.Embedding(nc + 1, hd) nc+1è‚¯å®šåŒ…å«äº†dn_clsçš„èŒƒå›´ 0-80
    dn_cls_embed = class_embed[dn_cls]  #  bs*num * 2 * num_group, 256
    
    # è¿™ä¸¤è¡Œä»£ç åˆ›å»ºäº†ä¸¤ä¸ªç”¨é›¶å¡«å……çš„å¼ é‡ï¼Œç”¨äºå­˜å‚¨ä¿®æ”¹åçš„ç±»åˆ«åµŒå…¥å’Œè¾¹ç•Œæ¡†åæ ‡
    padding_cls = torch.zeros(bs, num_dn, dn_cls_embed.shape[-1], device=gt_cls.device)
    padding_bbox = torch.zeros(bs, num_dn, 4, device=gt_bbox.device)
    
    # å½¢æˆä¸€ä¸ªé•¿æ•´æ•°åºåˆ— 0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3 ï¼ˆå¯¹åº”ä¸‰å¼ å›¾åƒï¼‰
    map_indices = torch.cat([torch.tensor(range(num), dtype=torch.long) for num in gt_groups])
   
    # å¯¹äºæ¯ä¸ªç»„ï¼ˆgroupï¼‰ï¼Œå°† map_indices ä¸­çš„æ¯ä¸ªå€¼éƒ½åŠ ä¸Šç›¸åº”çš„åç§»é‡ï¼Œåç§»é‡æ˜¯æ¯ä¸ªç»„ä¸­çš„æœ€å¤§æ•°é‡ max_nums ä¸ç»„çš„ç´¢å¼• i çš„ä¹˜ç§¯ã€‚
    # ç„¶åï¼Œä½¿ç”¨ torch.stack() å‡½æ•°å°†è¿™äº›å¼ é‡å †å èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º (num_group, num_gts)ï¼Œå…¶ä¸­ num_group æ˜¯ç»„çš„æ•°é‡ï¼Œnum_gts æ˜¯ä¸€ä¸ªæ‰¹æ¬¡ä¸­ ground truth çš„æ€»æ•°é‡ã€‚
    pos_idx = torch.stack([map_indices + max_nums * i for i in range(num_group)], dim=0)
   
    #  è¿™éƒ¨åˆ†ä»£ç é€šè¿‡åˆ—è¡¨æ¨å¯¼å¼ç”Ÿæˆäº†ä¸€ä¸ªå¼ é‡åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå¼ é‡éƒ½æ˜¯ map_indices åŠ ä¸Šç›¸åº”åç§»é‡çš„ç»“æœã€‚ èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒç»„
    # ï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼‰ï¼Œ ï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼‰+ 5 ...... ä¸€å…±æœ‰2 * num_groupä¸ª ç»´åº¦ä¸º2 * num_group * num_gts
    map_indices = torch.cat([map_indices + max_nums * i for i in range(2 * num_group)])

    '''
    padding_cls[(dn_b_idx, map_indices)] = dn_cls_embed: è¿™è¡Œä»£ç ä½¿ç”¨äº†å¼ é‡çš„é«˜çº§ç´¢å¼•åŠŸèƒ½ã€‚
    padding_cls æ˜¯ä¸€ä¸ªä¸‰ç»´å¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º (bs, num_dn, dn_cls_embed.shape[-1])ï¼Œå…¶ä¸­ bs æ˜¯æ‰¹æ¬¡å¤§å°ï¼Œnum_dn æ˜¯å¯¹æ¯”å»å™ªæ•°é‡ã€‚
    dn_b_idx æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ ·æœ¬æ‰€åœ¨æ‰¹æ¬¡ç´¢å¼•çš„ä¸€ç»´å¼ é‡ï¼Œmap_indices æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ­£æ ·æœ¬ç´¢å¼•çš„ä¸€ç»´å¼ é‡ï¼Œè¿™ä¸¤ä¸ªå¼ é‡ç»„åˆåœ¨ä¸€èµ·ï¼Œç”¨äºæŒ‡å®šåº”è¯¥å¡«å……çš„ä½ç½®ã€‚
    ç„¶åï¼Œå°† dn_cls_embed å¼ é‡å¡«å……åˆ°è¿™äº›ä½ç½®ä¸Šã€‚
    ç”±äº dn_cls_embed å’Œ padding_cls çš„æœ€åä¸€ä¸ªç»´åº¦å¤§å°ç›¸åŒï¼Œå› æ­¤å®ƒä»¬å¯ä»¥ç›´æ¥è¿›è¡Œèµ‹å€¼æ“ä½œã€‚
    '''

    padding_cls[(dn_b_idx, map_indices)] = dn_cls_embed
    padding_bbox[(dn_b_idx, map_indices)] = dn_bbox

    tgt_size = num_dn + num_queries
    attn_mask = torch.zeros([tgt_size, tgt_size], dtype=torch.bool)
    # Match query cannot see the reconstruct
    attn_mask[num_dn:, :num_dn] = True
    # Reconstruct cannot see each other
    for i in range(num_group):
        if i == 0:
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), max_nums * 2 * (i + 1):num_dn] = True
        if i == num_group - 1:
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), :max_nums * i * 2] = True
        else:
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), max_nums * 2 * (i + 1):num_dn] = True
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), :max_nums * 2 * i] = True
    dn_meta = {
        'dn_pos_idx': [p.reshape(-1) for p in pos_idx.cpu().split(list(gt_groups), dim=1)],
        'dn_num_group': num_group,
        'dn_num_split': [num_dn, num_queries]}

    return padding_cls.to(class_embed.device), padding_bbox.to(class_embed.device), attn_mask.to(
        class_embed.device), dn_meta


# #åˆ›å»ºç”¨äº denoisingï¼ˆå»å™ªï¼‰è¿‡ç¨‹çš„æŸ¥è¯¢ç»„
# def get_cdn_group_withoutcls(batch,
#                   num_queries,
#                   num_dn=100,
#                   box_noise_scale=1.0,
#                   nc=10,
#                   training=False):
#     """
#     Get contrastive denoising training group. This function creates a contrastive denoising training group with positive
#     and negative samples from the ground truths (gt). It applies noise to the class labels and bounding box coordinates,
#     and returns the modified labels, bounding boxes, attention mask and meta information.
#     è·å¾—å¯¹æ¯”å»å™ªè®­ç»ƒç»„ã€‚ è¯¥å‡½æ•°ä½¿ç”¨æ¥è‡ªåŸºæœ¬äº‹å® (gt) çš„æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬åˆ›å»ºå¯¹æ¯”å»å™ªè®­ç»ƒç»„ã€‚ å®ƒå°†å™ªå£°åº”ç”¨äºç±»æ ‡ç­¾å’Œè¾¹ç•Œæ¡†åæ ‡ï¼Œå¹¶è¿”å›ä¿®æ”¹åçš„æ ‡ç­¾ã€è¾¹ç•Œæ¡†ã€æ³¨æ„åŠ›æ©ç å’Œå…ƒä¿¡æ¯ã€‚
#     Args:
#         batch (dict): A dict that includes 'gt_cls' (torch.Tensor with shape [num_gts, ]), 'gt_bboxes'
#             (torch.Tensor with shape [num_gts, 4]), 'gt_groups' (List(int)) which is a list of batch size length
#             indicating the number of gts of each image.
#             å®ƒæ˜¯æ‰¹å¤§å°é•¿åº¦çš„åˆ—è¡¨ï¼ŒæŒ‡ç¤ºæ¯ä¸ªå›¾åƒçš„ gts æ•°é‡ã€‚
#         num_classes (int): Number of classes.
#         num_queries (int): Number of queries.
#         class_embed (torch.Tensor): Embedding weights to map class labels to embedding space.
#         num_dn (int, optional): Number of denoising. Defaults to 100.
#         cls_noise_ratio (float, optional): Noise ratio for class labels. Defaults to 0.5.
#         box_noise_scale (float, optional): Noise scale for bounding box coordinates. Defaults to 1.0.
#         training (bool, optional): If it's in training mode. Defaults to False.

#     Returns:
#         (Tuple[Optional[Tensor], Optional[Tensor], Optional[Tensor], Optional[Dict]]): The modified class embeddings,
#             bounding boxes, attention mask and meta information for denoising. If not in training mode or 'num_dn'
#             is less than or equal to 0, the function returns None for all elements in the tuple.
#     """

#     if (not training) or num_dn <= 0:
#         return None, None, None, None
#     # è¿™æ®µä»£ç è·å–äº†è¾“å…¥ batch ä¸­çš„ gt_groupsï¼Œè®¡ç®—äº†æ€»çš„ ground truth æ•°é‡ä»¥åŠæ‰¹æ¬¡ä¸­æœ€å¤§çš„ ground truth æ•°é‡ã€‚
#     # å¦‚æœæœ€å¤§æ•°é‡ä¸º 0ï¼Œåˆ™è¯´æ˜æ²¡æœ‰ ground truthï¼Œç›´æ¥è¿”å› Noneã€‚
#     gt_groups = batch['gt_groups']
#     total_num = sum(gt_groups) # æ‰€æœ‰å›¾åƒä¸­ä¸€å…±æœ‰å¤šå°‘gts
#     max_nums = max(gt_groups) # æ‰€æœ‰å›¾åƒä¸­æœ€å¤§çš„gtså€¼
#     if max_nums == 0:
#         return None, None, None, None
#     # è¿™æ®µä»£ç è®¡ç®—äº†æ¯ä¸ªæ ·æœ¬ç»„ä¸­çš„å¯¹æ¯”å»å™ªæ•°é‡ï¼Œå¹¶ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç»„ã€‚ç»„æ•°ä¸º 100/æœ€å¤§çš„gtså€¼
#     num_group = num_dn // max_nums 
#     num_group = 1 if num_group == 0 else num_group
#     # Pad gt to max_num of a batch
#     bs = len(gt_groups)
#     gt_cls = batch['cls']  # (bs*num, ) [num_gts, ]
#     gt_bbox = batch['bboxes']  # bs*num, 4 [num_gts, 4]
#     b_idx = batch['batch_idx']

#     # Each group has positive and negative queries.
#     dn_cls = gt_cls.repeat(2 * num_group)  # (2*num_group*bs*num, ) å¤åˆ¶ä¸¤ä»½ä»¥åŠåˆ†ç»„ç”¨äºç”Ÿäº§dn
#     dn_bbox = gt_bbox.repeat(2 * num_group, 1)  # 2*num_group*bs*num, 4
#     dn_b_idx = b_idx.repeat(2 * num_group).view(-1)  # (2*num_group*bs*num, )

#     # Positive and negative mask
#     # (bs*num*num_group, ), the second total_num*num_group part as negative samples
#     # PyTorch ä¸­çš„ torch.arange å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªä» 0 åˆ° total_num * num_group - 1 çš„æ•´æ•°åºåˆ— 
#     # ç”±äº total_num * num_group ä»£è¡¨äº†æ€»çš„æ ·æœ¬æ•°é‡ï¼Œæ‰€ä»¥åŠ ä¸Šè¿™ä¸ªå€¼ç›¸å½“äºå°†åºåˆ—ä¸­çš„ç´¢å¼•ç§»åŠ¨åˆ°è¡¨ç¤ºè´Ÿæ ·æœ¬çš„ä½ç½®ã€‚
#     neg_idx = torch.arange(total_num * num_group, dtype=torch.long, device=gt_bbox.device) + num_group * total_num

#     if box_noise_scale > 0:
#         # å°†è¾¹ç•Œæ¡†åæ ‡ dn_bbox ä» (x_center, y_center, width, height) çš„æ ¼å¼è½¬æ¢ä¸º (x_min, y_min, x_max, y_max) çš„æ ¼å¼ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ known_bbox ä¸­ã€‚
#         known_bbox = xywh2xyxy(dn_bbox)
#         # é¦–å…ˆï¼Œå®ƒä» dn_bbox çš„æœ€åä¸¤ä¸ªç»´åº¦ï¼ˆå³å®½åº¦å’Œé«˜åº¦ï¼‰ä¸­æå–äº†å€¼ï¼Œç„¶åä¹˜ä»¥ 0.5ï¼Œè¡¨ç¤ºå™ªå£°èŒƒå›´ä¸ºè¾¹ç•Œæ¡†å®½åº¦å’Œé«˜åº¦çš„ä¸€åŠã€‚
#         # æ¥ç€ï¼Œä½¿ç”¨ repeat() æ–¹æ³•å°†è¿™ä¸ªç»“æœæ²¿ç€ç¬¬äºŒç»´é‡å¤äº†ä¸¤æ¬¡ï¼Œä»¥ä¾¿åº”ç”¨äºæ¯ä¸ªè¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦
#         diff = (dn_bbox[..., 2:] * 0.5).repeat(1, 2) * box_noise_scale  # 2*num_group*bs*num, 4
#         # è¿™è¡Œä»£ç ç”Ÿæˆäº†ä¸€ä¸ªä¸ dn_bbox å¼ é‡ç›¸åŒå½¢çŠ¶çš„éšæœºæ•´æ•°å¼ é‡ï¼Œå€¼ä¸º 0 æˆ– 1ï¼Œå¹¶ä¹˜ä»¥ 2.0 åå‡å» 1.0ï¼Œå¾—åˆ°äº†ä¸€ä¸ªåŒ…å« -1 å’Œ 1 çš„å¼ é‡ï¼Œç”¨äºè¡¨ç¤ºå™ªå£°çš„æ–¹å‘ï¼ˆå·¦å³ä¸Šä¸‹ï¼‰
#         rand_sign = torch.randint_like(dn_bbox, 0, 2) * 2.0 - 1.0
#         # è¿™è¡Œä»£ç ç”Ÿæˆäº†ä¸€ä¸ªä¸ dn_bbox å¼ é‡ç›¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡ï¼Œå…¶ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä»å‡åŒ€åˆ†å¸ƒ [0, 1) ä¸­éšæœºé‡‡æ ·çš„ã€‚
#         rand_part = torch.rand_like(dn_bbox)
#         # è¿™è¡Œä»£ç å¯¹éƒ¨åˆ†éšæœºå™ªå£°å¢åŠ äº† 1.0ï¼Œç”¨äºç”Ÿæˆä¸€éƒ¨åˆ†è¾¹ç•Œæ¡†çš„å™ªå£°ï¼Œç¡®ä¿å®ƒä»¬æ˜¯è´Ÿæ ·æœ¬ã€‚è®©è¿™éƒ¨åˆ†æ ·æœ¬åœ¨[1,2]ä¹‹é—´ï¼Œè¿œç¦»çœŸå®å€¼å½¢æˆè´Ÿæ ·æœ¬
#         rand_part[neg_idx] += 1.0
#         # è¿™è¡Œä»£ç å°†éšæœºå™ªå£°ä¹˜ä»¥éšæœºæ–¹å‘ï¼Œä»¥è·å–æœ€ç»ˆçš„å™ªå£°å€¼
#         rand_part *= rand_sign
#         #  è¿™è¡Œä»£ç å°†å™ªå£°åº”ç”¨åˆ°è¾¹ç•Œæ¡†çš„åæ ‡ä¸Šã€‚
#         known_bbox += rand_part * diff
#         # è¿™è¡Œä»£ç ç¡®ä¿è¾¹ç•Œæ¡†çš„åæ ‡åœ¨åˆç†çš„èŒƒå›´å†…ï¼Œå³åœ¨å›¾åƒèŒƒå›´å†…ã€‚
#         known_bbox.clip_(min=0.0, max=1.0)
#         dn_bbox = xyxy2xywh(known_bbox)
#         dn_bbox = torch.logit(dn_bbox, eps=1e-6)  # inverse sigmoid

#     num_dn = int(max_nums * 2 * num_group)  # total denoising queries
#     # class_embed = self.denoising_class_embed.weght = nn.Embedding(nc + 1, hd) nc+1è‚¯å®šåŒ…å«äº†dn_clsçš„èŒƒå›´ 0-80
#     # è¿™é‡Œå°†ç±»åˆ«ç¼–å·è½¬ä¸ºç½®ä¿¡åº¦åˆ†å¸ƒ
#     b = dn_cls.shape[0]
#     one_hot = torch.zeros((b,  nc + 1), dtype=torch.float, device=gt_cls.device)
#     #targetsä¸ºå›¾åƒä¸­å­˜åœ¨çš„ç±»åˆ«ï¼Œscatter_ä¸ºæ’å…¥æ“ä½œï¼Œpred_scoresä¸º
#     one_hot.scatter_(1, dn_cls.unsqueeze(-1), 1)
#     dn_cls_embed = one_hot[..., :-1]
#     # dn_cls_embed= torch.nn.functional.one_hot(dn_cls, num_classes=nc).to(torch.float)

    
#     # è¿™ä¸¤è¡Œä»£ç åˆ›å»ºäº†ä¸¤ä¸ªç”¨é›¶å¡«å……çš„å¼ é‡ï¼Œç”¨äºå­˜å‚¨ä¿®æ”¹åçš„ç±»åˆ«åµŒå…¥å’Œè¾¹ç•Œæ¡†åæ ‡
#     padding_cls = torch.zeros(bs, num_dn, dn_cls_embed.shape[-1], device=gt_cls.device)
#     padding_bbox = torch.zeros(bs, num_dn, 4, device=gt_bbox.device)
    
#     # å½¢æˆä¸€ä¸ªé•¿æ•´æ•°åºåˆ— 0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3 ï¼ˆå¯¹åº”ä¸‰å¼ å›¾åƒï¼‰
#     map_indices = torch.cat([torch.tensor(range(num), dtype=torch.long) for num in gt_groups])
   
#     # å¯¹äºæ¯ä¸ªç»„ï¼ˆgroupï¼‰ï¼Œå°† map_indices ä¸­çš„æ¯ä¸ªå€¼éƒ½åŠ ä¸Šç›¸åº”çš„åç§»é‡ï¼Œåç§»é‡æ˜¯æ¯ä¸ªç»„ä¸­çš„æœ€å¤§æ•°é‡ max_nums ä¸ç»„çš„ç´¢å¼• i çš„ä¹˜ç§¯ã€‚
#     # ç„¶åï¼Œä½¿ç”¨ torch.stack() å‡½æ•°å°†è¿™äº›å¼ é‡å †å èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º (num_group, num_gts)ï¼Œå…¶ä¸­ num_group æ˜¯ç»„çš„æ•°é‡ï¼Œnum_gts æ˜¯ä¸€ä¸ªæ‰¹æ¬¡ä¸­ ground truth çš„æ€»æ•°é‡ã€‚
#     pos_idx = torch.stack([map_indices + max_nums * i for i in range(num_group)], dim=0)
   
#     #  è¿™éƒ¨åˆ†ä»£ç é€šè¿‡åˆ—è¡¨æ¨å¯¼å¼ç”Ÿæˆäº†ä¸€ä¸ªå¼ é‡åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå¼ é‡éƒ½æ˜¯ map_indices åŠ ä¸Šç›¸åº”åç§»é‡çš„ç»“æœã€‚ èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒç»„
#     # ï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼‰ï¼Œ ï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼‰+ 5 ...... ä¸€å…±æœ‰2 * num_groupä¸ª
#     map_indices = torch.cat([map_indices + max_nums * i for i in range(2 * num_group)])

#     '''
#     padding_cls[(dn_b_idx, map_indices)] = dn_cls_embed: è¿™è¡Œä»£ç ä½¿ç”¨äº†å¼ é‡çš„é«˜çº§ç´¢å¼•åŠŸèƒ½ã€‚
#     padding_cls æ˜¯ä¸€ä¸ªä¸‰ç»´å¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º (bs, num_dn, dn_cls_embed.shape[-1])ï¼Œå…¶ä¸­ bs æ˜¯æ‰¹æ¬¡å¤§å°ï¼Œnum_dn æ˜¯å¯¹æ¯”å»å™ªæ•°é‡ã€‚
#     dn_b_idx æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ ·æœ¬æ‰€åœ¨æ‰¹æ¬¡ç´¢å¼•çš„ä¸€ç»´å¼ é‡ï¼Œmap_indices æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ­£æ ·æœ¬ç´¢å¼•çš„ä¸€ç»´å¼ é‡ï¼Œè¿™ä¸¤ä¸ªå¼ é‡ç»„åˆåœ¨ä¸€èµ·ï¼Œç”¨äºæŒ‡å®šåº”è¯¥å¡«å……çš„ä½ç½®ã€‚
#     ç„¶åï¼Œå°† dn_cls_embed å¼ é‡å¡«å……åˆ°è¿™äº›ä½ç½®ä¸Šã€‚
#     ç”±äº dn_cls_embed å’Œ padding_cls çš„æœ€åä¸€ä¸ªç»´åº¦å¤§å°ç›¸åŒï¼Œå› æ­¤å®ƒä»¬å¯ä»¥ç›´æ¥è¿›è¡Œèµ‹å€¼æ“ä½œã€‚
#     '''
#     padding_cls[(dn_b_idx, map_indices)] = dn_cls_embed
#     padding_bbox[(dn_b_idx, map_indices)] = dn_bbox

#     tgt_size = num_dn + num_queries
#     attn_mask = torch.zeros([tgt_size, tgt_size], dtype=torch.bool)
#     # Match query cannot see the reconstruct
#     attn_mask[num_dn:, :num_dn] = True
#     # Reconstruct cannot see each other
#     for i in range(num_group):
#         if i == 0:
#             attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), max_nums * 2 * (i + 1):num_dn] = True
#         if i == num_group - 1:
#             attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), :max_nums * i * 2] = True
#         else:
#             attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), max_nums * 2 * (i + 1):num_dn] = True
#             attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), :max_nums * 2 * i] = True
#     dn_meta = {
#         'dn_pos_idx': [p.reshape(-1) for p in pos_idx.cpu().split(list(gt_groups), dim=1)],
#         'dn_num_group': num_group,
#         'dn_num_split': [num_dn, num_queries]}

#     return padding_cls.to('cuda'), padding_bbox.to('cuda'), attn_mask.to(
#         'cuda'), dn_meta


#åˆ›å»ºç”¨äº denoisingï¼ˆå»å™ªï¼‰è¿‡ç¨‹çš„æŸ¥è¯¢ç»„
def get_cdn_group_withoutcls(batch,
                  num_queries,
                  num_dn=100,
                  box_noise_scale=1.0,
                  training=False):
    """
    Get contrastive denoising training group. This function creates a contrastive denoising training group with positive
    and negative samples from the ground truths (gt). It applies noise to the class labels and bounding box coordinates,
    and returns the modified labels, bounding boxes, attention mask and meta information.
    è·å¾—å¯¹æ¯”å»å™ªè®­ç»ƒç»„ã€‚ è¯¥å‡½æ•°ä½¿ç”¨æ¥è‡ªåŸºæœ¬äº‹å® (gt) çš„æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬åˆ›å»ºå¯¹æ¯”å»å™ªè®­ç»ƒç»„ã€‚ å®ƒå°†å™ªå£°åº”ç”¨äºç±»æ ‡ç­¾å’Œè¾¹ç•Œæ¡†åæ ‡ï¼Œå¹¶è¿”å›ä¿®æ”¹åçš„æ ‡ç­¾ã€è¾¹ç•Œæ¡†ã€æ³¨æ„åŠ›æ©ç å’Œå…ƒä¿¡æ¯ã€‚
    Args:
        batch (dict): A dict that includes 'gt_cls' (torch.Tensor with shape [num_gts, ]), 'gt_bboxes'
            (torch.Tensor with shape [num_gts, 4]), 'gt_groups' (List(int)) which is a list of batch size length
            indicating the number of gts of each image.
            å®ƒæ˜¯æ‰¹å¤§å°é•¿åº¦çš„åˆ—è¡¨ï¼ŒæŒ‡ç¤ºæ¯ä¸ªå›¾åƒçš„ gts æ•°é‡ã€‚
        num_classes (int): Number of classes.
        num_queries (int): Number of queries.
        class_embed (torch.Tensor): Embedding weights to map class labels to embedding space.
        num_dn (int, optional): Number of denoising. Defaults to 100.
        cls_noise_ratio (float, optional): Noise ratio for class labels. Defaults to 0.5.
        box_noise_scale (float, optional): Noise scale for bounding box coordinates. Defaults to 1.0.
        training (bool, optional): If it's in training mode. Defaults to False.

    Returns:
        (Tuple[Optional[Tensor], Optional[Tensor], Optional[Tensor], Optional[Dict]]): The modified class embeddings,
            bounding boxes, attention mask and meta information for denoising. If not in training mode or 'num_dn'
            is less than or equal to 0, the function returns None for all elements in the tuple.
    """

    if (not training) or num_dn <= 0:
        return None, None, None
    # è¿™æ®µä»£ç è·å–äº†è¾“å…¥ batch ä¸­çš„ gt_groupsï¼Œè®¡ç®—äº†æ€»çš„ ground truth æ•°é‡ä»¥åŠæ‰¹æ¬¡ä¸­æœ€å¤§çš„ ground truth æ•°é‡ã€‚
    # å¦‚æœæœ€å¤§æ•°é‡ä¸º 0ï¼Œåˆ™è¯´æ˜æ²¡æœ‰ ground truthï¼Œç›´æ¥è¿”å› Noneã€‚
    gt_groups = batch['gt_groups']
    total_num = sum(gt_groups) # æ‰€æœ‰å›¾åƒä¸­ä¸€å…±æœ‰å¤šå°‘gts
    max_nums = max(gt_groups) # æ‰€æœ‰å›¾åƒä¸­æœ€å¤§çš„gtså€¼
    if max_nums == 0:
        return None, None, None
    # è¿™æ®µä»£ç è®¡ç®—äº†æ¯ä¸ªæ ·æœ¬ç»„ä¸­çš„å¯¹æ¯”å»å™ªæ•°é‡ï¼Œå¹¶ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç»„ã€‚ç»„æ•°ä¸º 100/æœ€å¤§çš„gtså€¼
    num_group = num_dn // max_nums 
    num_group = 1 if num_group == 0 else num_group
    # Pad gt to max_num of a batch
    bs = len(gt_groups)
    gt_bbox = batch['bboxes']  # bs*num, 4 [num_gts, 4]
    b_idx = batch['batch_idx']

    # Each group has positive and negative queries.
    dn_bbox = gt_bbox.repeat(2 * num_group, 1)  # 2*num_group*bs*num, 4
    dn_b_idx = b_idx.repeat(2 * num_group).view(-1)  # (2*num_group*bs*num, )

    # Positive and negative mask
    # (bs*num*num_group, ), the second total_num*num_group part as negative samples
    # PyTorch ä¸­çš„ torch.arange å‡½æ•°åˆ›å»ºäº†ä¸€ä¸ªä» 0 åˆ° total_num * num_group - 1 çš„æ•´æ•°åºåˆ— 
    # ç”±äº total_num * num_group ä»£è¡¨äº†æ€»çš„æ ·æœ¬æ•°é‡ï¼Œæ‰€ä»¥åŠ ä¸Šè¿™ä¸ªå€¼ç›¸å½“äºå°†åºåˆ—ä¸­çš„ç´¢å¼•ç§»åŠ¨åˆ°è¡¨ç¤ºè´Ÿæ ·æœ¬çš„ä½ç½®ã€‚
    neg_idx = torch.arange(total_num * num_group, dtype=torch.long, device=gt_bbox.device) + num_group * total_num

    if box_noise_scale > 0:
        # å°†è¾¹ç•Œæ¡†åæ ‡ dn_bbox ä» (x_center, y_center, width, height) çš„æ ¼å¼è½¬æ¢ä¸º (x_min, y_min, x_max, y_max) çš„æ ¼å¼ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨ known_bbox ä¸­ã€‚
        known_bbox = xywh2xyxy(dn_bbox)
        # é¦–å…ˆï¼Œå®ƒä» dn_bbox çš„æœ€åä¸¤ä¸ªç»´åº¦ï¼ˆå³å®½åº¦å’Œé«˜åº¦ï¼‰ä¸­æå–äº†å€¼ï¼Œç„¶åä¹˜ä»¥ 0.5ï¼Œè¡¨ç¤ºå™ªå£°èŒƒå›´ä¸ºè¾¹ç•Œæ¡†å®½åº¦å’Œé«˜åº¦çš„ä¸€åŠã€‚
        # æ¥ç€ï¼Œä½¿ç”¨ repeat() æ–¹æ³•å°†è¿™ä¸ªç»“æœæ²¿ç€ç¬¬äºŒç»´é‡å¤äº†ä¸¤æ¬¡ï¼Œä»¥ä¾¿åº”ç”¨äºæ¯ä¸ªè¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦
        diff = (dn_bbox[..., 2:] * 0.5).repeat(1, 2) * box_noise_scale  # 2*num_group*bs*num, 4
        # è¿™è¡Œä»£ç ç”Ÿæˆäº†ä¸€ä¸ªä¸ dn_bbox å¼ é‡ç›¸åŒå½¢çŠ¶çš„éšæœºæ•´æ•°å¼ é‡ï¼Œå€¼ä¸º 0 æˆ– 1ï¼Œå¹¶ä¹˜ä»¥ 2.0 åå‡å» 1.0ï¼Œå¾—åˆ°äº†ä¸€ä¸ªåŒ…å« -1 å’Œ 1 çš„å¼ é‡ï¼Œç”¨äºè¡¨ç¤ºå™ªå£°çš„æ–¹å‘ï¼ˆå·¦å³ä¸Šä¸‹ï¼‰
        rand_sign = torch.randint_like(dn_bbox, 0, 2) * 2.0 - 1.0
        # è¿™è¡Œä»£ç ç”Ÿæˆäº†ä¸€ä¸ªä¸ dn_bbox å¼ é‡ç›¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡ï¼Œå…¶ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä»å‡åŒ€åˆ†å¸ƒ [0, 1) ä¸­éšæœºé‡‡æ ·çš„ã€‚
        rand_part = torch.rand_like(dn_bbox)
        # è¿™è¡Œä»£ç å¯¹éƒ¨åˆ†éšæœºå™ªå£°å¢åŠ äº† 1.0ï¼Œç”¨äºç”Ÿæˆä¸€éƒ¨åˆ†è¾¹ç•Œæ¡†çš„å™ªå£°ï¼Œç¡®ä¿å®ƒä»¬æ˜¯è´Ÿæ ·æœ¬ã€‚è®©è¿™éƒ¨åˆ†æ ·æœ¬åœ¨[1,2]ä¹‹é—´ï¼Œè¿œç¦»çœŸå®å€¼å½¢æˆè´Ÿæ ·æœ¬
        rand_part[neg_idx] += 1.0
        # è¿™è¡Œä»£ç å°†éšæœºå™ªå£°ä¹˜ä»¥éšæœºæ–¹å‘ï¼Œä»¥è·å–æœ€ç»ˆçš„å™ªå£°å€¼
        rand_part *= rand_sign
        #  è¿™è¡Œä»£ç å°†å™ªå£°åº”ç”¨åˆ°è¾¹ç•Œæ¡†çš„åæ ‡ä¸Šã€‚
        known_bbox += rand_part * diff
        # è¿™è¡Œä»£ç ç¡®ä¿è¾¹ç•Œæ¡†çš„åæ ‡åœ¨åˆç†çš„èŒƒå›´å†…ï¼Œå³åœ¨å›¾åƒèŒƒå›´å†…ã€‚
        known_bbox.clip_(min=0.0, max=1.0)
        dn_bbox = xyxy2xywh(known_bbox)
        dn_bbox = torch.logit(dn_bbox, eps=1e-6)  # inverse sigmoid

    num_dn = int(max_nums * 2 * num_group)  # total denoising queries
    # class_embed = self.denoising_class_embed.weght = nn.Embedding(nc + 1, hd) nc+1è‚¯å®šåŒ…å«äº†dn_clsçš„èŒƒå›´ 0-80
    # è¿™é‡Œå°†ç±»åˆ«ç¼–å·è½¬ä¸ºç½®ä¿¡åº¦åˆ†å¸ƒ

    
    # è¿™ä¸¤è¡Œä»£ç åˆ›å»ºäº†ä¸¤ä¸ªç”¨é›¶å¡«å……çš„å¼ é‡ï¼Œç”¨äºå­˜å‚¨ä¿®æ”¹åçš„ç±»åˆ«åµŒå…¥å’Œè¾¹ç•Œæ¡†åæ ‡
    padding_bbox = torch.zeros(bs, num_dn, 4, device=gt_bbox.device)
    
    # å½¢æˆä¸€ä¸ªé•¿æ•´æ•°åºåˆ— 0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3 ï¼ˆå¯¹åº”ä¸‰å¼ å›¾åƒï¼‰
    map_indices = torch.cat([torch.tensor(range(num), dtype=torch.long) for num in gt_groups])
   
    # å¯¹äºæ¯ä¸ªç»„ï¼ˆgroupï¼‰ï¼Œå°† map_indices ä¸­çš„æ¯ä¸ªå€¼éƒ½åŠ ä¸Šç›¸åº”çš„åç§»é‡ï¼Œåç§»é‡æ˜¯æ¯ä¸ªç»„ä¸­çš„æœ€å¤§æ•°é‡ max_nums ä¸ç»„çš„ç´¢å¼• i çš„ä¹˜ç§¯ã€‚
    # ç„¶åï¼Œä½¿ç”¨ torch.stack() å‡½æ•°å°†è¿™äº›å¼ é‡å †å èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªå¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º (num_group, num_gts)ï¼Œå…¶ä¸­ num_group æ˜¯ç»„çš„æ•°é‡ï¼Œnum_gts æ˜¯ä¸€ä¸ªæ‰¹æ¬¡ä¸­ ground truth çš„æ€»æ•°é‡ã€‚
    pos_idx = torch.stack([map_indices + max_nums * i for i in range(num_group)], dim=0)
   
    #  è¿™éƒ¨åˆ†ä»£ç é€šè¿‡åˆ—è¡¨æ¨å¯¼å¼ç”Ÿæˆäº†ä¸€ä¸ªå¼ é‡åˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå¼ é‡éƒ½æ˜¯ map_indices åŠ ä¸Šç›¸åº”åç§»é‡çš„ç»“æœã€‚ èƒ½æœ‰æ•ˆåŒºåˆ†ä¸åŒç»„
    # ï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼‰ï¼Œ ï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ2ï¼Œ3ï¼‰+ 5 ...... ä¸€å…±æœ‰2 * num_groupä¸ª
    map_indices = torch.cat([map_indices + max_nums * i for i in range(2 * num_group)])

    '''
    padding_cls[(dn_b_idx, map_indices)] = dn_cls_embed: è¿™è¡Œä»£ç ä½¿ç”¨äº†å¼ é‡çš„é«˜çº§ç´¢å¼•åŠŸèƒ½ã€‚
    padding_cls æ˜¯ä¸€ä¸ªä¸‰ç»´å¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º (bs, num_dn, dn_cls_embed.shape[-1])ï¼Œå…¶ä¸­ bs æ˜¯æ‰¹æ¬¡å¤§å°ï¼Œnum_dn æ˜¯å¯¹æ¯”å»å™ªæ•°é‡ã€‚
    dn_b_idx æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ ·æœ¬æ‰€åœ¨æ‰¹æ¬¡ç´¢å¼•çš„ä¸€ç»´å¼ é‡ï¼Œmap_indices æ˜¯ä¸€ä¸ªè¡¨ç¤ºæ­£æ ·æœ¬ç´¢å¼•çš„ä¸€ç»´å¼ é‡ï¼Œè¿™ä¸¤ä¸ªå¼ é‡ç»„åˆåœ¨ä¸€èµ·ï¼Œç”¨äºæŒ‡å®šåº”è¯¥å¡«å……çš„ä½ç½®ã€‚
    ç„¶åï¼Œå°† dn_cls_embed å¼ é‡å¡«å……åˆ°è¿™äº›ä½ç½®ä¸Šã€‚
    ç”±äº dn_cls_embed å’Œ padding_cls çš„æœ€åä¸€ä¸ªç»´åº¦å¤§å°ç›¸åŒï¼Œå› æ­¤å®ƒä»¬å¯ä»¥ç›´æ¥è¿›è¡Œèµ‹å€¼æ“ä½œã€‚
    '''

    padding_bbox[(dn_b_idx, map_indices)] = dn_bbox

    tgt_size = num_dn + num_queries
    attn_mask = torch.zeros([tgt_size, tgt_size], dtype=torch.bool)
    # Match query cannot see the reconstruct
    attn_mask[num_dn:, :num_dn] = True
    # Reconstruct cannot see each other
    for i in range(num_group):
        if i == 0:
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), max_nums * 2 * (i + 1):num_dn] = True
        if i == num_group - 1:
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), :max_nums * i * 2] = True
        else:
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), max_nums * 2 * (i + 1):num_dn] = True
            attn_mask[max_nums * 2 * i:max_nums * 2 * (i + 1), :max_nums * 2 * i] = True
    dn_meta = {
        'dn_pos_idx': [p.reshape(-1) for p in pos_idx.cpu().split(list(gt_groups), dim=1)],
        'dn_num_group': num_group,
        'dn_num_split': [num_dn, num_queries]}

    return padding_bbox.to('cuda'), attn_mask.to('cuda'), dn_meta
